{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3 - TIME SERIES DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the cleaned CSV file\n",
    "file_path = '../data/a1_worksheet_cleaned.csv'\n",
    "\n",
    "df = pd.read_csv(file_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 4)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Real GDP at market prices</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Consumer price inflation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900</td>\n",
       "      <td>181160.0</td>\n",
       "      <td>3.68</td>\n",
       "      <td>4.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>184975.0</td>\n",
       "      <td>4.88</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1902</td>\n",
       "      <td>187757.0</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1903</td>\n",
       "      <td>186016.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1904</td>\n",
       "      <td>188156.0</td>\n",
       "      <td>6.91</td>\n",
       "      <td>-0.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Real GDP at market prices  Unemployment rate  \\\n",
       "0  1900                   181160.0               3.68   \n",
       "1  1901                   184975.0               4.88   \n",
       "2  1902                   187757.0               5.15   \n",
       "3  1903                   186016.0               5.60   \n",
       "4  1904                   188156.0               6.91   \n",
       "\n",
       "   Consumer price inflation  \n",
       "0                      4.06  \n",
       "1                     -0.30  \n",
       "2                      0.00  \n",
       "3                      1.10  \n",
       "4                     -0.40  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Real GDP at market prices</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Consumer price inflation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1996</td>\n",
       "      <td>1243709.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1997</td>\n",
       "      <td>1282602.0</td>\n",
       "      <td>6.97</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1998</td>\n",
       "      <td>1323527.0</td>\n",
       "      <td>6.26</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1999</td>\n",
       "      <td>1366983.0</td>\n",
       "      <td>5.98</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2000</td>\n",
       "      <td>1418176.0</td>\n",
       "      <td>5.46</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Real GDP at market prices  Unemployment rate  \\\n",
       "96   1996                  1243709.0               8.10   \n",
       "97   1997                  1282602.0               6.97   \n",
       "98   1998                  1323527.0               6.26   \n",
       "99   1999                  1366983.0               5.98   \n",
       "100  2000                  1418176.0               5.46   \n",
       "\n",
       "     Consumer price inflation  \n",
       "96                       2.40  \n",
       "97                       1.82  \n",
       "98                       1.56  \n",
       "99                       1.33  \n",
       "100                      0.80  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. Define strict and weak stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the lecture 6 (Time Series 2), a time series $\\{x_t\\}$ is *strictly stationary* if the joint distribution of \n",
    "$(x_{t_1}, x_{t_2}, \\ldots, x_{t_m})$ is the same as the joint distribution of \n",
    "$(x_{t_1+h}, x_{t_2+h}, \\ldots, x_{t_m+h})$ for any collection of time indices $t_1 \\leq t_2 \\leq \\ldots \\leq t_m$ and for all $h \\geq 1$. This implies that the statistical properties of the series are invariant under time shifts.\n",
    "\n",
    "On the other hand, a stochastic process $\\{x_t\\}$ is *weakly stationary* if:\n",
    "1. $\\mathbb{E}[x_t]$ is constant over time.\n",
    "2. $\\text{Var}(x_t)$ is constant over time.\n",
    "3. $\\text{Cov}(x_t, x_{t+h})$ does not depend on $t$, only on $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Explain ergodicity and state the ergodic theorem. Illustrate with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ergodicity* is the property of a stochastic process where the statistical properties estimated over a single realization are the same as those estimated over the ensemble. It is like the process \"forgets\" its initial conditions as time progresses. The two conditions for ergodicity to hold are:\n",
    "- The process is strictly stationnary\n",
    "- The auto-correlation of order $k$ tends to 0 as $k$ approaches infinity.\n",
    "\n",
    "*Ergodicity Theorem*: If a process $\\{y_t\\}$ is strictly stationary and ergodic, and $E(y_t) < \\infty$, then the time average of the process converges to the ensemble mean as the number of observations $T$ tends to infinity.\n",
    "\n",
    "*Example*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. Why do we need both stationarity and ergodicity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need both *stationarity* and *ergodicity* because:\n",
    "- *Stationarity* ensures that the statistical properties of the process, like mean, variance, and covariance, remain constant over time, making the analysis and modeling consistent.\n",
    "- *Ergodicity* ensures that the time averages calculated from a single realization of the process are representative of the ensemble averages. This allows us to estimate the process's characteristics from a single long time series without needing multiple realizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. Explain “spurious regression”.\n",
    "\n",
    "Spurious regression occurs when two or more non-stationary time series are regressed, producing misleadingly high $R^2$ values. It arises from shared trends or stochastic drifts in unrelated variables, rather than a genuine connection. For example, regressing GDP and temperature over time might falsely show a strong relationship because both share upward trends, though they are unrelated.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28. Make all time series stationary by computing the difference between the original variable and a moving average of order $2 \\times 10$. Give the formula for the exact weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29. Using the original dataset, test the unit root hypothesis for all variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30. Transform all variables so that they are stationary using either your answers to questions 28 or 29."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31. Explain the difference between ACF and PACF.\n",
    "\n",
    "\n",
    "The *auto-correlation function* (ACF) measures the correlation between a time series $y_t$ and its lagged values $y_{t-k}$. Its formula is given by:\n",
    "\n",
    "$$\n",
    "\\rho_k = \\frac{\\text{Cov}(y_t, y_{t-k})}{\\text{Var}(y_t)}\n",
    "$$\n",
    "\n",
    "And the *partial auto-correlation function* measures the correlation between $y_t$ and $y_{t-k}$ after controlling for the effects of intermediate lags $y_{t-1}, y_{t-2}, \\dots, y_{t-(k-1)}$.\n",
    "\n",
    "In essence, ACF measures total correlation (direct + indirect) at each lag, while PACF isolates the direct correlation for each lag.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32. Plot and comment on the ACF and PACF of all variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33. Explain the principle of parsimony and its relationship with Ockham’s razor using the theory of information criterion.\n",
    "\n",
    "The principle of parsimony states that among many model, we should prioritize simpler models that adequatly explain the data, avoiding unnecessary complexity. This aligns with Ockham's razor, which supports parsimony by favoring models with fewer parameters to prevent overfitting.\n",
    "\n",
    "In model selection, this principle is applied using information criteria like the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC). Both balance model fit and complexity, with lower values indicating better models. AIC favors models with good fit but avoids overfitting by penalizing extra parameters, while BIC penalizes complexity more strongly, especially for large datasets. These criteria ensure model selection follows Ockham's Razor by promoting simplicity without sacrificing performance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34. Explain the problem of auto-correlation of the errors.\n",
    "\n",
    "*Autocorrelation of errors* occurs when the residuals ($u_t$) in a regression model are correlated with one another across time. This violates the classical OLS assumption that the errors are independently distributed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 35. Using only stationary variables, run a regression of GDP on `constant`, `unemployment`, and `inflation` and test the hypothesis of no-autocorrelation of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 36. Regardless of your answer to question 35, correct auto-correlation with GLS. Test again for the presence of auto-correlation. Comment on your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 37. For all variables, construct their lag 1 and lag 2 variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 38. Run a regression of GDP on `constant`, lag 1 `unemployment`, lag 2 `unemployment`, lag 1 `inflation`, and lag 2 `inflation`. What is the number of observations and why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 39. State and test the no-Granger causality hypothesis of unemployment on GDP at the 1% level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40. Divide the sample into two groups: 1900-1960 and 1961-2000. Test the stability of coefficients between the two periods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 41. Test the structural breakpoint using a trim ratio of 30% at the 1% level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 42. Divide the sample into 3 periods of equal length. Test that the coefficients of the second and the third periods are equal. Formulate the null hypothesis and interpret your results.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absol-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
